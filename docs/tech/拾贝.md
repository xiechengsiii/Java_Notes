##### 用亦或运算实现swap

```java
//在做快排的时候，swap用亦或运算踩了一个坑：
private  void swap(int[] nums, int i, int j){
   nums[i] ^= nums[j];
   nums[j] ^= nums[i];
   nums[i] ^= nums[j]; 
}
//注意这里如果  i ==j  会让这个位置的元素变为0！！！！
```



##### cache的相关知识

 [缓存的基本原理](https://zhuanlan.zhihu.com/p/102293437)  这边文章介绍的挺好的

```java
//两种写法效率是不同的：
int[10][128] arr;
    
for (i = 0; i < 10; i++)
        for (j = 0; j < 128; j++);
                arr[i][j] = 1;

for (i = 0; i < 128; i++)
        for (j = 0; j < 10; j++);
                arr[j][i] = 1;
假设cache line = 64Bytes， 采取写分配和写回策略，arr数组内存首地址是64字节对齐
如果缓存大小比较小，不能缓存整个数组，那么第一种写法的效率是要高于第二种写法的：
    写法1:首先arr[0][0] = 1,arr[0][0]不在cache中，发生cache miss，
        然后会存主存中度去arr[0][0] - arr[0][15]的数据到缓存中（64字节）,接着后面的1 - 15
        都是cache hit。相当于每1一次cache miss， 15次cache hit
    
    写法2:arr[0][0] = 1, 然后读一个缓存行大小的数据进入缓存arr[0][0] - arr[0][15];
		arr[1][0] = 1, 又发生cache miss, 所以又读一个64字节的数据进入缓存行；
        ...
        如果缓存比较小(极端情况比如只有一个缓存行大小)，会发生大量的cache miss而导致效率较低
 只有缓存分配策略为写分配的情况才适用上述情况，如果不支持写分配，写指令只会更新数据到主存，没有加载数据到cache中这一步（读分配）
     
```



##### 套接字通信的建立

![image-20200619212335500](E:\Typora\imgs\image-20200619212335500.png)

##### get和post的区别

一篇文章讲[get和post的区别](https://www.zhihu.com/question/28586791/answer/767316172)，讲的很详细 

截取一部分：

**浏览器的POST需要发两个请求吗**

上文中的"HTTP  格式“清楚的显示了HTTP请求可以被大致分为“请求头”和“请求体”两个部分。使用HTTP时大家会有一个约定，即所有的**“控制类”**信息应该放在请求头中，具体的数据放在请求体里“。于是服务器端在解析时，总是会先完全解析全部的请求头部。这样，**服务器端总是希望能够了解请求的控制信息后，就能决定这个请求怎么进一步处理，是拒绝，还是根据content-type去调用相应的解析器处理数据，或者直接用zero copy转发**。

比如在用Java写服务时，请求处理代码总是能从HttpSerlvetRequest里getParameter/Header/url。这些信息都是请求头里的，框架直接就解析了。而对于请求体，只提供了一个inputstream，如果开发人员觉得应该进一步处理，就自己去读取和解析请求体。这就能体现出服务器端对请求头和请求体的不同处理方式。

举个实际的例子，比如写一个上传文件的服务，请求url中包含了文件名称，请求体中是个尺寸为几百兆的压缩二进制流。服务器端接收到请求后，就可以先拿到请求头部，查看用户是不是有权限上传，文件名是不是符合规范等。如果不符合，就不再处理请求体的数据了，直接丢弃。而不用等到整个请求都处理完了再拒绝。

为了进一步优化，客户端可以利用HTTP的Continued协议 来这样做：客户端总是先发送所有请求头给服务器，让服务器校验。如果通过了，服务器回复“100 - Continue”，客户端再把剩下的数据发给服务器。如果请求被拒了，服务器就回复个400之类的错误，这个交互就终止了。这样，就可以避免浪费带宽传请求体。但是代价就是会多一次Round Trip。如果刚好请求体的数据也不多，那么一次性全部发给服务器可能反而更好。

基于此，客户端就能做一些优化，比如内部设定一次POST的数据超过1KB就先只发“请求头”，否则就一次性全发。客户端甚至还可以做一些Adaptive的策略，统计发送成功率，如果成功率很高，就总是全部发等等。不同浏览器，不同的客户端（curl，postman）可以有各自的不同的方案。不管怎样做，优化目的总是在提高数据吞吐和降低带宽浪费上做一个折衷。

因此到底是发一次还是发N次，客户端可以很灵活的决定。因为不管怎么发都是符合HTTP协议的，因此我们应该视为这种优化是一种实现细节，而不用扯到GET和POST本身的区别上。更不要当个什么世纪大发现。

##### 正向代理与反向代理

正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。

1、**正向代理其实是客户端的代理**，帮助客户端访问其无法访问的服务器资源。**反向代理则是服务器的代理**，帮助服务器做负载均衡，安全防护等。

2、**正向代理一般是客户端架设的**，比如在自己的机器上安装一个代理软件。而**反向代理一般是服务器架设的**，比如在自己的机器集群中部署一个反向代理服务器。

3、**正向代理中，服务器不知道真正的客户端到底是谁**，以为访问自己的就是真实的客户端。而在**反向代理中，客户端不知道真正的服务器是谁**，以为自己访问的就是真实的服务器。

4、正向代理和反向代理的作用和目的不同。**正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。**

##### XSS
​	Cross-Site Scripting（跨站脚本攻击）简称 XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。
​	XSS 的本质是：**恶意代码未经过滤，与网站正常的代码混在一起**；浏览器无法分辨哪些脚本是可信的，导致恶意脚本被执行。

