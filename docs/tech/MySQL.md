# MySQL Notes

## MySQL索引以及存储结构

1.关于**自适应哈哈希索引的理解**

​	类似于下图的搜索模式

​	对于一些常用的热点键值，innodb内部缓冲池会创建基于B+Tree的哈希索引，直接对叶子节点进行映射。

​	不过前提是查询条件必须一样，并且达到了一定的数量才会开启自适应哈希。

​		![image-20200521091834420](E:\Typora\imgs\image-20200521091834420.png)

2.[一篇介绍Innodb页结构的文章，简单易懂全面](https://mp.weixin.qq.com/s?__biz=MzIxNTQ3NDMzMw==&mid=2247483678&idx=1&sn=913780d42e7a81fd3f9b747da4fba8ec&chksm=979688eca0e101fa0913c3d2e6107dfa3a6c151a075c8d68ab3f44c7c364d9510f9e1179d94d&scene=21#wechat_redirect)

在一页中存储引擎是通过二分法定位到对应的记录的：页结构中的Page Directory 记录了每组记录中最后一条记录的偏移量，具体寻找行记录的过程：

​	1.通过二分法确定该记录对应的槽

​	2.通过记录的 ``next_record``属性遍历链表查找对应的记录

![image-20200530215710075](E:\Typora\imgs\image-20200530215710075.png)



3.索引总结

- **最左前缀匹配原则**。这是非常重要、非常重要、非常重要（重要的事情说三遍）的原则，MySQL会一直向右匹配直到遇到范围查询`（>,<,BETWEEN,LIKE）`就停止匹配。

- 尽量选择**区分度高的列作为索引**，区分度的公式是 `COUNT(DISTINCT col) / COUNT(*)`。表示字段不重复的比率，比率越大我们扫描的记录数就越少。

- **索引列不能参与计算，尽量保持列“干净”**。比如，`FROM_UNIXTIME(create_time) = '2016-06-06'` 就不能使用索引，原因很简单，**B+树中存储的都是数据表中的字段值**，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成 ： `create_time = UNIX_TIMESTAMP('2016-06-06')`。

- 尽可能的**扩展索引**，不要新建立索引。比如表中已经有了a的索引，现在要加（a,b）的索引，那么只需要修改原来的索引即可。



## MySQL的IO行为

 1. ``innodb_flush_log_at_trx_commit``

    0  日志缓冲写到之日志文件，每秒刷新一次 ， 但是事物提交时不做任何事

    1  ==日志缓冲写到日志文件==，并且每次事物提交时都刷新到持久化存储（innodb默认）

    2 每次提交任务时，==把日志缓冲写到日志文件（操作系统缓存）==，但是并不刷新， 每秒做一次刷新

    注意==将日志缓冲写到日志文件==和==将日志持久化存储==是不同的， 前者只是将innodb的内存缓存转移到操作系统的缓存，并没有做到真正的持久化存储

    ![image-20200520100641550](C:\Users\XXX\AppData\Roaming\Typora\typora-user-images\image-20200520100641550.png)
    
    log Buffer 处于用户空间的内存， 要写到磁盘上的Log Files 要经过OS Buffer (当然 ， 如果开启了 0_Direct不需要）	

``0_DIRECT`` 

​	可以使OS不要缓存数据，也不做预读，这个选项完全关闭了操作系统缓存，使所有读写都直接通过

存储设备，避免双重缓冲	

2.随机IO和顺序IO

<img src="E:\Typora\imgs\image-20200806111204899.png" alt="image-20200806111204899" style="zoom:67%;" />

- 顺序IO就是读写操作的访问地址连续，读写磁头可以以最小的移动访问到下一个块(数据)，数据备份和日志记录等业务是顺序IO业务；

- 随机IO是指读写操作时间连续，但访问地址不连续，随机分布在磁盘的地址空间中。随机IO通常只要查找特定的行，而IO粒度是页级的，大部分是不需要查找的数据；而顺序IO所读取的数据通常都包括了数据块的所有行，没有浪费。

  产生随机IO的业务有OLTP服务，SQL，即时消息服务等,

随机读取往往有多次磁盘寻道，而顺序读取一般只需要扫描一次数据，所以缓存能对随机IO有很大地提升，对顺序IO也有提升，但是不如随机IO提升的明显。

缓存可以延缓写入并且几种操作

- 多次写入， 一次刷新

- IO合并 许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次磁盘操作完成物理写入

  通过预写日志将随机IO变为顺序IO

3.几种日志

参考这篇[文章](https://zhuanlan.zhihu.com/p/58011817)

- redo log  事务日志,保证事务持久化的   同时减少了提交事务时的开销。随机IO变为顺序IO，不需要每个事务提交的时候都把缓冲池的脏块flush到磁盘中。

- undo log  提供回滚，和MVCC功能

- binlog  用于恢复数据，主从模式下用于复制。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作并且记录了语句发生时间、执行时长、操作数据等其它额外信息。

  除了上面介绍的几个作用外，binlog对于事务存储引擎的崩溃恢复也有非常重要的作用。在开启binlog的情况下，为了保证binlog与redo的一致性，MySQL将采用事务的两阶段提交协议。当MySQL系统发生崩溃时，事务在存储引擎内部的状态可能为prepared和commit两种。对于prepared状态的事务，是进行提交操作还是进行回滚操作，这时需要参考binlog：如果事务在binlog中存在，那么将其提交；如果不在binlog中存在，那么将其回滚，这样就保证了数据在主库和从库之间的一致性。

## 优化

- ``varchar``

  虽然varchar是变长的，实际存储的是字符串的实际长度，但是在比如排序的时候，会为需要排序的数据创建一个固定大小的缓冲，此时是根据varchar定义的最大长度而不是存储数据的最大长度。所以“数据多长就定义多长”
  
  **高性能MySQL**中提到，对于Innodb，最重要的选项是下面两个：
  
- ``innodb_buffer_pool_size``

  win10下可以在``my.ini``下对改参数进行修改(5.5竟然不能动态修改)

  该参数主要缓存数据，索引，插入数据时的缓冲

  ``innodb_buffer_pool_size`` 总是``innodb_buffer_pool_instances``*``innodb_buffer_pool_chunk_size``的整数倍
  
  一个合适的计算``innodb_buffer_pool_size``的公式：
  
  ``innodb_buffer_pool_size``= 系统可用内存 - 系统正常运行内存 - （峰值时的连接数 * 每个连接需要的内存）
  
  不过更大的缓冲池会使得mysql服务在重启和关闭的时候花费很长时间  **比如启动时的系统预热**

- ``innodb_log_file_size``

  ![image-20200525151919811](E:\Typora\imgs\image-20200525151919811.png)

  ``innodb_log_file_size`` * ``innodb_log_files_in_group``不能超过最大值

由于事务修改的数据和索引通常会映射到表空间的随机位置里，所以这些变更到磁盘需要很对随机IO。

innodb用日志把**随机IO变成顺序IO**（追加的方式写入），一旦日志安全写到磁盘，事务就持久化了。当然，Innodb最后会把变更写到数据文件，因为日志文件是有固定的大小的。innodb的日志是环形方式写的：当写到日志的尾部，会重新跳转到开头继续写。 innodb使用一个后台线程智能地刷新这些变更到数据文件，相当于缓和了IO系统的压力。

对于  ``innodb_log_file_size``，如果太大，恢复起来太慢，太小，当一个日志文件写满后，innodb会自动切换到另一个日志文件，而且会触发数据库的checkpoint ，这回导致innodb缓存脏页的小批量刷新，会明显降低innodb的性能。一个经验是，日志文件的全部大小应该足够容纳服务器一个小时的活动内容。



## 事务与锁

[参考这篇文章](https://tech.meituan.com/2014/08/20/innodb-lock.html)

加锁，是基于索引的，是对数据涉及的聚簇索引和非聚簇索引锁定（最终都还是锁定主键吧）。索引失效的情况下，会变成表锁，表锁的性质是排它锁。

```mysql
uid（PK） varchar 
user_name varchar 
user_sex int


begin;
select * from t_user where uid = 2 lock in share mode;
#都先不执行commit，以便观察现象
#commit;

select查询虽然使用的检索依据是uid，但是设置检索条件时uid的varchar类型却被错误的使用成了int类型。那么数据表将不再使用索引进行检索，转而进行全表扫秒。这是一种典型的索引失效情况，最终现象是，在执行以上同一查询语句的两个事务中，有一个返回了查询结果，但是另外一个一直为等待状态。	
```



1.四种隔离级别

​	``READ UNCOMMITED``    ``READ COMMITED``   ``REAPEATABLE READ``   ``SERIALIZABLE``

​	是SQL的标准定义，不同数据库会有不同的实现，MySQL在 ``REPEATABLE READ``的隔离级别下，是可以避免幻读的

2.版本链

​	对于INNODB的表，它的行记录都有两个必要的隐藏列：

- trx_id 每次对某条记录进行改动时，都会把对应的事物ID赋值给改trx_id
- roll_pointer 每次对记录进行改动时，这个隐藏列会存一个指针，通过这个指针可以找到该记录修改前的信息

**3.readview**

​	对于``READ UNCOMMITED``，直接读取最新的记录版本就行；``SERIALIZABLE``,使用加锁的方式来访问记录；``READ COMMITED``和``REAPEATABLE READ``就需要通过版本链和``readview``配合完成了，核心问题就是**判断版本链中哪个版本应该是当前事务应该读的**

​	实际上版本并非物理存在的，而是通过undo log 计算出来的。

​	readview中比较重要的四个属性 ：

- ``m_ids``  生成``readview``时，当前系统活跃（未提交的）读写事务的事务id列表
- ``min_trx_id`` 生成``readview``时，当前系统活跃（未提交的）读写事务的事务id列表``m_ids``的最小值
- ``max_trx_id`` 生成``readview``时系统应该分配给下一个事务的id值
- ``creator_trx_id`` 生成该``readview``的事务的事务id

**4.MVCC**

在使用``READ COMMITED``和``REAPEATABLE READ``两种隔离级别的事务在执行普通的select操作时访问记录的**版本链**的过程，可以使不同事务读-写并发执行，提高并发性能（ 不涉及到加锁），主要是能高效地读

``READ COMMITED``和``REAPEATABLE READ``很大不同：生成``readview``时机不同：

- ``READ COMMITED``每次进行select操作都会生成一个``readview``
- ``REAPEATABLE READ``只在第一次select操作前生成一个``readview``,之后的查询操作重复使用这个``readview``从而实现可重复读

**快照读** 

快照读就是读取数据的时候会根据一定规则读取事务可见版本的数据。

```mysql
 select * from .... where ... 
```



**当前读**  会加锁

```mysql
select * from .... where ... for update 
select * from .... where ... lock in share mode 
update .... set .. where ... 
delete from. . where ..
```





[看这篇文章的讨论](https://zhuanlan.zhihu.com/p/64576887)

开启begin的时候，其实是没有tx_id产生的，必须要执行select之类的操作语句之后才有事务ID的产生，即执行第一个操作的时候才会产生tx_id

5.锁

- 读锁  共享锁  select * from t1  where id  = 1 lock in share mode

- 写锁  排它锁 select ... for update

- select   普通的select操作，Innodb不会加任何锁  也就是事物A对某行加了写锁，事物B 执行普通的select操作是不会阻塞的。 想要select操作也加锁，可以：

  select ... for update  写锁

  select * from t1  where id  = 1 lock in share mode 读锁

- Gap锁 为了解决幻读

  **死锁：**
  
  死锁造成的根本原因和上层MySQL服务和下层InnoDB引擎的协调方式有关：在上层MySQL服务和下层InnoDB引擎配合进行Update、Delete和Insert操作时， 对满足条件的索引加X锁的操作是逐步进行的。
  
  当InnoDB进行update、delete或者insert操作时，如果有多条记录满足操作要求，那么InnoDB引擎会锁定一条记录（实际上是相应的索引）然后再对这条记录进行处理，完成后再锁定下一条记录进行处**理。这样依次循环直到所有满足条件的数据被处理完，最后再统一释放事务中的所有锁**。如果这个过程中某个将要锁定的记录已经被其它事务抢先锁定，则本事务就进入等待状态，一直等待到锁定的资源被释放为止。
  
  ![image-20200912101909063](E:\Typora\imgs\image-20200912101909063.png)

![image-20200912101922799](E:\Typora\imgs\image-20200912101922799.png)

几个网上找到的案例：

![image-20200912105314592](E:\Typora\imgs\image-20200912105314592.png)

![image-20200912105108336](E:\Typora\imgs\image-20200912105108336.png)

​		这里的分析，最终还是锁定的主键

- 如何避免死锁？

  在工作过程中偶尔会遇到死锁问题，虽然这种问题遇到的概率不大，但每次遇到的时候要想彻底弄懂其原理并找到解决方案却并不容易。其实，对于 MySQL 的 InnoDb 存储引擎来说，死锁问题是避免不了的，没有哪种解决方案可以说完全解决死锁问题，但是我们可以通过一些可控的手段，降低出现死锁的概率。

  1. 如上面的案例一和案例三所示，对索引加锁顺序的不一致很可能会导致死锁，所以如果可以，尽量以相同的顺序来访问索引记录和表。在程序以批量方式处理数据的时候**，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能；**
  2. 如上面的案例二所示，Gap 锁往往是程序中导致死锁的真凶，由于默认情况下 MySQL 的隔离级别是 RR，所以如果能确定幻读和不可重复读对应用的影响不大，可以考虑将隔离级别改成 RC，可以避免 Gap 锁导致的死锁；
  3. **为表添加合理的索引，如果不走索引将会为表的每一行记录加锁，死锁的概率就会大大增大；**
  4. 我们知道 MyISAM 只支持表锁，它采用一次封锁技术来保证事务之间不会发生死锁，所以，我们也可以使用同样的思想，在事务中一次锁定所需要的所有资源，减少死锁概率；
  5. **避免大事务，尽量将大事务拆成多个小事务来处理**；因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高；
  6. 避免在同一时间点运行多个对同一表进行读写的脚本，特别注意加锁且操作数据量比较大的语句；我们经常会有一些定时脚本，避免它们在同一时间点运行；
  7. **设置锁等待超时参数**：`innodb_lock_wait_timeout`，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

mysql解除死锁

```mysql
1、查看是否有锁表
show OPEN TABLES where In_use > 0;
2、查询进程（如果你有SUPER权限，你可以看到所有线程。否则，只能看到你自己的线程）
show processlist;
3、杀死进程id（就是上面命令的id列）
kill id

1、查看在锁的事务
SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;
2、杀死进程id（就是上面命令的trx_mysql_thread_id列）
kill id

终止正在进行的事务？
```



## 高可用和可扩展



### 复制

原则：一个备库实例只有一个主库，一个主库可以由多个备库；每个备库必须有一个唯一的服务器ID

- 基于行的复制

  优点：几乎所有场景都适用，不需要串行化；不要建立查询计划并执行查询（减少CPU的使用）；更新一个不存在的行 时会报错；

  缺点：不知道执行了哪些SQL，不利于找到问题；

- 基于语句的复制（逻辑复制）

  优点：不占带宽，一条更新好几兆数据的语句可能只占几十个字节；出现问题好定位，灵活，表的列顺序不同，数据类型兼容都可以更新

  缺点：正在使用触发器或者存储过程，会有问题；必须串行化；

  **步骤**：

  1.在主库上，根据事务的提交顺序记录二进制日志

  2.备库启动一个IO线程与主库建立一个普通的客户端连接，备库会在主库上启动一个线程，执行binlog dump指令，将二进制日志的数据发送至备库（如果备库，会对主库造成很大的负载，备库将接受到的数据记录在relay log（中继日志）。

  3.备库的启动一个SQL线程从relay log中读取事件并在备库执行，实现备库数据的更新。**主库并发运行的查询只能在备库上串行化执行，因为备库只有一个SQL线程更新数据**，这是一个性能瓶颈。

  ![image-20200531170246859](E:\Typora\imgs\image-20200531170246859.png)

- 一主多备   适用于少量写大量读，备库只读，主库可以读和写。 当备库太多对主库造成过大的工作负载时，可以通过一个分发库解决。分发库实际上也是一个备库，唯一的目的就是提取主库的binary log文件，多个备库连接到主库从而降低主库的负载。

  ###### 	存在延迟，因而能读到脏数据   how to solve it?

  可以同步写操作：在多个备库上执行``MASTER_POS_WAIT()``,可以阻塞主库务直到备库赶上了设置的主库同步点，相当于设置了一个``CyclicBarrier``。但是当一个备库出现复制延迟时，可能花很长时间才能完成复制。

- 双主复制   会有很多冲突，比如同时向两台主库写数据，只能在两台服务器之间共享串行化写入 。可以采用主动-被动模式下的双主复制

### 避免单点失效

一般都是为系统增加冗余：增加空余容量和重复组件。

  

### 可扩展

- **垂直扩展**  

  在单机的基础上买更多强悍的硬件，但是总会遇到性能瓶颈：

  1.复杂的查询在MySQL内部是单线程的，只能使用一个CPU，无法利用多核

  2.数据非常庞大的时候，总会出现无法缓存的情况，内存成为瓶颈，导致很高的磁盘利用率。

- **水平扩展**   复制，拆分，数据分片

  1.什么时候要数据分片？

  ​	主从模式是适用于读多写少的场景。只有单台主库，无论备库多么多，写容量始终是无法扩展的。想要扩展写容量，就必须切分数据。



  

#   SQL语句

1.``group by `` 配合 ``having``对分组过滤。注意，where是基于行过滤，group by是基于分组

```mysql
select vend_id, count(*) as num_prods from products where product_price > 10 group by  vend_id having count(*)  > 2;
```

2.做项目的时候要对项目日志做分析，要统计某一个时间段内，每一小时或者每一天的日志数据

```mysql
//每一天
select DATA_FORMAT(trigger_time, '%Y-%m-%d') as triggerDay, count(id) as triggerCount from table 
where day between '2020-02-02' and '2020-03-03' group by triggerDay order by trigger_time;

//每一小时，可以用mysql自带的函数hour()
select Hour(trigger_time) as Hour, count(*) as Count from table where trigger_time between '2018_02_15 01:18:16' and '2018-02-05 17:18:16' group by Hour order by Hour
```

![image-20200902085502667](E:\Typora\imgs\image-20200902085502667.png)

![image-20200902085720523](E:\Typora\imgs\image-20200902085720523.png)

3.查询数据库表近7天的数据

```mysql
select count(*), date(create_time) as date from table where datediff(now(), create_time)
<= 6 group by day(create_time);
```



# tips

1. 建表规范

   https://juejin.cn/post/6844903928228757511

2. 索引的使用

不走索引的一些情况：

- 索引情况不好（索引列数据区分度太小，例如性别列），范围太大，扫表，这些都在Mysql内部优化器优化完之后发现不如扫表效率高。
- 列 参与运算：

```java
SELECT sname FROM stu WHERE age+10=30;SELECT sname FROM stu 
WHERE LEFT(date,4) <1990;
```

- 列参与正则表达式
- 隐式转换-字符串类型与数字比较：EXPLAIN SELECT * FROM `a` WHERE `a`=1;　如果是'1'则走索引
- LIKE语句中：

```java
SELECT * FROM `houdunwang` WHERE `uname` LIKE "%后盾%";
可以设置前缀索引，走前缀索引：SELECT * FROM `houdunwang` WHERE `uname` LIKE "后盾%";
SELECT * FROM `houdunwang` WHERE `uname` LIKE "%后盾"
```

- NOT IN语句
- IS NULL,　!=, not in 语句, 负向索引：not , not in, not like, <>, != ,!>,!<

索引设计

**索引是一把双刃剑，它可以提高查询效率但也会降低插入和更新的速度并占用磁盘空间。**

**在线上创建表的时候，一定要考虑好表的索引，这样避免线上MySQL性能问题带来的故障以及降低后续维护成本。没有索引的建表语句DBA大部分情况下都不会通过审核。**

- 1、单张表中索引数量建议不超过5个。
- 2、单个索引中的字段数不超过5个。
- 3、innodb主键推荐使用自增列，主键不应被修改，字符串不应该做主键，如果不指定主键，innodb会使用唯一且非空值索引代替。
- 4、如果是复合索引，区分度最大的字段放在索引前面。
- 5、核心SQL优先考虑覆盖索引。
- 6、区分度最大的字段放在索引前面。
- 7、避免冗余或重复索引：
- 8、合理创建联合索引（避免冗余), index(a,b,c)相当于index(a)、index(a,b)、index(a,b,c)。
- 9、不在低基数列上建立索引，例如‘性别’。
- 10、不在索引列进行数学运算和函数运算，保证索引列单独出现。比如：select * from table1 where col_age/2 < = 4 ，即使col_age列上有索引，也不会使用。但是若改为另一种写法：select * from table1 where col_age < = 4*2，这时就可以使用 col_age列上的索引。
- 11、尽量不要使用外键：对父表和子表的操作会相互影响，降低可用性。
- 12、不使用%前导的查询，如like“%xxx”，因为索引遵循最左匹配原则，因此这种查询无法使用索引，若必须使用左开头模糊匹配，建议使用INSTR替换like用法。
- 13、不使用反向查询，如not in / not like：无法使用索引，导致全表扫描全表/全索引扫描。
- 14、索引不是越多越好，按实际需要进行创建。索引创建越多，会有两个缺点：（1）数据增删改都要对多个索引进行同时更新，导致数据的写入性能低（2）生成查询执行计划时会考虑多个索引，导致数据的查询性能低。
- 15、索引对应的列的数据类型要尽量地“小”（能用int，不要用bigint，当然要考虑业务发展规模），这样可以提升读写的性能。

**查询语句**

1. 使用in代替or，in的值不超过200个。
2. 使用union all而不是union：Union将会按照字段的顺序进行排序；UNION ALL只是简单的将两个结果合并后就返回。从效率上说，UNION ALL 要比UNION快，所以，如果可以确认合并的两个结果集中不包含重复数据且不需要排序时的话，那么就使用UNION ALL。
3. 不使用select * ，避免消耗cpu、内存和网络带宽，具体来说有如下问题：

- select * 最大的问题是可能会多出一些不用的列，导致无法使用索引覆盖，最终大幅降低查询效率。
- select * 会导致传输多余的字段，增加数据的网络传输成本。
- select * 由于获取了不必要的列，字段较多时，占用的内存较大，mysql分配的内存无法承载所有数据，因此会多次分布内存，当时本次分配的内容存用完后，再次分配。频繁分配内存会导致CPU繁忙和查询延时增大。

1. 在进行数据插入的时候，尽量保证主键或者索引列的逐渐递增，避免忽大忽小，否则会导致页分裂导致数据插入性能低下。
2. 当数据量比较大时，不建议使用 limit m,n 来做分页，考虑使用 id（或者其它关键字段）> ? limit m 的方式分页
