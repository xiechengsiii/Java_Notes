### Netty 

#### 一些前置知识

##### 阻塞/非阻塞IO与异步/同步

- 一个关于进程切换的示例图

  ![img](https://pic1.zhimg.com/80/v2-5672054f97fd77f78420fed6b442536e_1440w.jpg?source=1940ef5c)

当发生中断或者系统调用时，CPU的控制权会从当前进程转移到操作系统内核。操作系统在进行进程切换时，需要进行一系列的内存读写操作， 这带来了一定的开销：对于一个运行着 UNIX 系统的现代 PC 来说， 进程切换通常至少需要花费 300 us 的时间。

- 进程状态图

![img](https://pic2.zhimg.com/80/v2-e88514c2e604c4ac538c402f1788862c_1440w.jpg?source=1940ef5c)

进程的**阻塞**往往个system call紧密相关。一个进程进入waiting状态，要么主动调用wait()或者sleep()，要么就是调用system call。而 System Call 因为涉及到了 I/O 操作， 不能立即完成， 于是内核就会先将该进程置为等待状态， 调度其他进程的运行， 等到 它所请求的 I/O 操作完成了以后， 再将其状态更改回 ready 。

- **非阻塞I/O 系统调用( nonblocking system call )** 和 **异步I/O系统调用 （asychronous system call）**的区别是：
  - 一个**非阻塞I/O 系统调用 read()** 操作立即返回的是任何可以立即拿到的数据， 可以是完整的结果， 也可以是不完整的结果， 还可以是一个空值。
  - **异步I/O系统调用** read（）结果必须是完整的， 但是这个操作完成的通知可以延迟到将来的一个时间点。

- UNIX 的IO模型

  - 异步I/O 是指用户程序发起IO请求后，不等待数据，同时操作系统内核负责I/O操作把数据从内核拷贝到用户程序的缓冲区后通知应用程序。数据拷贝是由操作系统内核完成，用户程序从一开始就没有等待数据，发起请求后不参与任何IO操作，等内核通知完成。

  - 同步I/O 就是非异步IO的情况，也就是用户程序要参与把数据拷贝到程序缓冲区（例如java的InputStream读字节流过程）。
  - 同步IO里的非阻塞 是指用户程序发起IO操作请求后不等待数据，而是调用会立即返回一个标志信息告知条件不满足，数据未准备好，从而用户请求程序继续执行其它任务。执行完其它任务，用户程序会**主动轮询查**看IO操作条件是否满足，如果满足，则用户程序亲自参与拷贝数据动作。

  因此，在unix IO模型的语境下，同步和异步的区别在于数据拷贝阶段是否需要完全由操作系统处理。阻塞和非阻塞操作是针对发起IO请求操作后是否有立刻返回一个标志信息而不让请求线程等待。

##### 长连接

​	顾名思义，与短连接相反，指在一**个TCP连接**上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持，也就是长时间保持客户端与服务端的连接状态。而短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接，一般银行都使用短连接。 

​	优点：长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，较适用长连接。

​	缺点：如果并发量很大，成千上万都建立长连接，server总有抗不出的时候。

​	基于**长连接**，可以实现**数据的实时传递**：客户端与服务端建立好网络长连接，服务方有相关数据，直接通过长连接通道推送到客户端。其优点是及时，一旦有数据变更，客户端立马能感知到。

​	数据交互有两种模式：Push（推模式）、Pull（拉模式）。推模式是指服务方有相关数据，直接通过长连接主动推送到客户端。拉模式指的是客户端主动向服务端发出请求，拉取数据。	

websocket，long polling 以及 ajax轮询也可以实现信息的实时传递：

- long polling（长轮询）    要求服务器有很高的并发处理能力

  long polling是拉模式的一种：客户端发起Long Polling，此时如果服务端没有相关数据，会hold住请求，直到服务端有相关数据，或者等待一定时间超时才会返回。返回后，**客户端又会立即再次发起下一次Long Polling**。这种方式也是对拉模式的一个优化，解决了拉模式数据通知不及时，以及减少了大量的无效轮询次数。

- websocket  

  是一种协议，定义了一种在通过一个单一的 socket 在网络上进行全双工通讯的通道。基于长连接，由**客户主动询问**，转换为**服务器（推送）有信息的时候就发送**。

  - 除了第一次建立连接需要发送header，之后所有数据的交换不需要http header了，因此提高了信息交换效率，大大减少了不必要的网络流量。

  - 相比于轮询，信息的延迟也降低:

    ![轮询和WebSocket应用程序之间的延迟比较](https://segmentfault.com/img/bVbnYjK?w=504&h=360)

    ​    轮询应用程序响应完成时必须将新请求发送到服务器。比如这个新请求需要另一个`50ms`，在此期间服务器不能向浏览器发送任何消息，从而导致额外的服务器内存消耗和延时。

- http1.1 协议中的keep-alive字段，也可以保持长连接，和websocket有什么不同？

  我认为是websocket的长连接只要客户端/服务端不主动关闭，TCP连接可以一直保持，此外的长连接还是指应用层面的:客户端和服务端可以不受限制的相互通信（全双工）；而http1.1的keep alive，TCP连接可以保持一段时间（自己设置），但是HTTP请求是串行的，即 请求---响应（一个http请求到这里就结束了），请求--响应，并没有保持应用层面的长连接。

##### 异步回调

netty中的实现类异步回调机制，有点类似于java中的future, 不过java中的future有个问题，就是当你想获取异步执行结果时，要通过future.get()方法，这一步还是阻塞的！而且我们无法确定到底异步任务何时执行完毕，提前get了，就还是阻塞。

可以基于``监听器模式``实现类似于netty的回调小demo。

复杂的场景，比如A任务执行完之后 同时执行B,C任务。可以利用``CompleteableFuture``这个类



#### Netty是什么

[官网介绍](https://netty.io/)：Netty is a **NIO client server framework** which enables quick and easy development of network applications such as protocol servers and clients. It greatly simplifies and streamlines network programming such as TCP and UDP socket server.

有个理解误区：`Netty`说自己是异步事件驱动的框架，那么其网络io也是异步的。 实际上，异步事件驱动框架体现在所有**的`I/O`操作是异步的，所有的`IO`调用会立即返回，并不保证调用成功与否**，但是调用会返回`ChannelFuture`，`netty`会通过`ChannelFuture`通知你调用是成功了还是失败了亦或是取消了。而这个``IO``操作的任务是交给Netty的NIO底层处理，是同步非阻塞的。

- 一定比tomcat好么？

  两者的最大区别在在于通信协议。tomcat是基于Http协议的，他的实质是一个基于http协议的web容器，但是Netty不一样，他能通过编程自定义各种协议，因为netty能够通过codec自己来编码/解码字节流，完成类似redis访问的功能，这就是netty和tomcat最大的不同。不能说netty的性能就一定比tomcat性能高，tomcat从6.x开始就支持了nio模式，并且后续还有APR模式——一种通过jni调用apache网络库的模式，相比于旧的bio模式，并发性能得到了很大提高，特别是APR模式，而netty是否比tomcat性能更高，取决于netty程序的编写。
  
##### 线程模型

基于reactor模式的线程模型：

- 单reactor单线程

  ![深入研究Netty之线程模型详解2](https://res-static.hc-cdn.cn/fms/img/902d614415f21a4f73939b4e7b7e70fd1603448103731.png)

- 单reactor多线程

  ![深入研究Netty之线程模型详解3](https://res-static.hc-cdn.cn/fms/img/507fb85af3f5a8d242c6414b0ec766ef1603448103732.png)

- 主从reactor多线程

  ![深入研究Netty之线程模型详解4](https://res-static.hc-cdn.cn/fms/img/d11538a81f64d5c67d9572f804d8dbb11603448103732.png)

服务端使用一个独立的主Reactor线程池来处理客户端连接，当服务端收到连接请求时，从主线程池中随机选择一个Reactor线程作为Acceptor线程处理连接；链路建立成功后，将新创建的SocketChannel注册到sub reactor线程池的某个Reactor线程上，由它处理后续的I/O操作。

##### zeroCopy

用于在数据读写中减少甚至完全避免不必要的CPU拷贝，减少内存带宽的占用，提高执行效率。除了netty，kafka（基于``sendfile``和DMA Gather Copy）、rocketMQ(基于``mmap`` 和``write``)都实现了零拷贝。

- java的标准io处理

  ![io](https:github.com/xiechengsiii/Java_Notes/blob/master/pics/netty-io.png)

  ​    完成一次完整的数据读写，至少需要从底层硬件读到内核空间，再读到用户文件，又从用户空间写入内核空间，再写入底层硬件。此外，底层通过write、read等函数进行I/O系统调用时，需要传入数据所在缓冲区**起始地址和长度**，由于JVM GC的存在，导致对象在堆中的位置往往会发生移动，移动后传入系统函数的地址参数就不是真正的缓冲区地址了，可能导致读写出错，为了解决上面的问题，使用标准I/O进行系统调用时，还会额外导致一次数据拷贝：把数据从JVM的堆内拷贝到堆外的连续空间内存(堆外内存)。所以总共经历6次数据拷贝，执行效率较低。

  - netty的零拷贝

  疑问：使用具备零拷贝特性的 transfer() 方法拷贝文件，一定会比传统 I/O 的方式更高效吗？

