# MySQL Notes

## MySQL索引以及存储结构

1.关于**自适应哈哈希索引的理解**

​	类似于下图的搜索模式

​	对于一些常用的热点键值，innodb内部缓冲池会创建基于B+Tree的哈希索引，直接对叶子节点进行映射。

​	不过前提是查询条件必须一样，并且达到了一定的数量才会开启自适应哈希。

​		![image-20200521091834420](E:\Typora\imgs\image-20200521091834420.png)

2.[一篇介绍Innodb页结构的文章，简单易懂全面](https://mp.weixin.qq.com/s?__biz=MzIxNTQ3NDMzMw==&mid=2247483678&idx=1&sn=913780d42e7a81fd3f9b747da4fba8ec&chksm=979688eca0e101fa0913c3d2e6107dfa3a6c151a075c8d68ab3f44c7c364d9510f9e1179d94d&scene=21#wechat_redirect)

在一页中存储引擎是通过二分法定位到对应的记录的：页结构中的Page Directory 记录了每组记录中最后一条记录的偏移量，具体寻找行记录的过程：

​	1.通过二分法确定该记录对应的槽

​	2.通过记录的 ``next_record``属性遍历链表查找对应的记录

![image-20200530215710075](E:\Typora\imgs\image-20200530215710075.png)



## MySQL的IO行为

 1. ``innodb_flush_log_at_trx_commit``

    0  日志缓冲写到之日志文件，每秒刷新一次 ， 但是事物提交时不做任何事

    1  ==日志缓冲写到日志文件==，并且每次事物提交时都刷新到持久化存储（innodb默认）

    2 每次提交任务时，==把日志缓冲写到日志文件（操作系统缓存）==，但是并不刷新， 每秒做一次刷新

    注意==将日志缓冲写到日志文件==和==将日志持久化存储==是不同的， 前者只是将innodb的内存缓存转移到操作系统的缓存，并没有做到真正的持久化存储

    ![image-20200520100641550](C:\Users\XXX\AppData\Roaming\Typora\typora-user-images\image-20200520100641550.png)
    
    log Buffer 处于用户空间的内存， 要写到磁盘上的Log Files 要经过OS Buffer (当然 ， 如果开启了 0_Direct不需要）	

``0_DIRECT`` 

​	可以使OS不要缓存数据，也不做预读，这个选项完全关闭了操作系统缓存，使所有读写都直接通过

存储设备，避免双重缓冲	

2.随机IO和顺序IO

<img src="E:\Typora\imgs\image-20200806111204899.png" alt="image-20200806111204899" style="zoom:67%;" />

- 顺序IO就是读写操作的访问地址连续，读写磁头可以以最小的移动访问到下一个块(数据)，数据备份和日志记录等业务是顺序IO业务；

- 随机IO是指读写操作时间连续，但访问地址不连续，随机分布在磁盘的地址空间中。随机IO通常只要查找特定的行，而IO粒度是页级的，大部分是不需要查找的数据；而顺序IO所读取的数据通常都包括了数据块的所有行，没有浪费。

  产生随机IO的业务有OLTP服务，SQL，即时消息服务等,

随机读取往往有多次磁盘寻道，而顺序读取一般只需要扫描一次数据，所以缓存能对随机IO有很大地提升，对顺序IO也有提升，但是不如随机IO提升的明显。

缓存可以延缓写入并且几种操作

- 多次写入， 一次刷新

- IO合并 许多不同部分的数据可以在内存中修改，并且这些修改可以合并在一起，通过一次磁盘操作完成物理写入

  通过预写日志将随机IO变为顺序IO

3.几种日志

参考这篇[文章](https://zhuanlan.zhihu.com/p/58011817)

- redo log  事务日志,保证事务持久化的   同时减少了提交事务时的开销。随机IO变为顺序IO，不需要每个事务提交的时候都把缓冲池的脏块flush到磁盘中。

- undo log  提供回滚，和MVCC功能

- binlog  用于恢复数据，主从模式下用于复制。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作并且记录了语句发生时间、执行时长、操作数据等其它额外信息。

  除了上面介绍的几个作用外，binlog对于事务存储引擎的崩溃恢复也有非常重要的作用。在开启binlog的情况下，为了保证binlog与redo的一致性，MySQL将采用事务的两阶段提交协议。当MySQL系统发生崩溃时，事务在存储引擎内部的状态可能为prepared和commit两种。对于prepared状态的事务，是进行提交操作还是进行回滚操作，这时需要参考binlog：如果事务在binlog中存在，那么将其提交；如果不在binlog中存在，那么将其回滚，这样就保证了数据在主库和从库之间的一致性。

## 优化

- ``varchar``

  虽然varchar是变长的，实际存储的是字符串的实际长度，但是在比如排序的时候，会为需要排序的数据创建一个固定大小的缓冲，此时是根据varchar定义的最大长度而不是存储数据的最大长度。所以“数据多长就定义多长”
  
  **高性能MySQL**中提到，对于Innodb，最重要的选项是下面两个：
  
- ``innodb_buffer_pool_size``

  win10下可以在``my.ini``下对改参数进行修改(5.5竟然不能动态修改)

  该参数主要缓存数据，索引，插入数据时的缓冲

  ``innodb_buffer_pool_size`` 总是``innodb_buffer_pool_instances``*``innodb_buffer_pool_chunk_size``的整数倍
  
  一个合适的计算``innodb_buffer_pool_size``的公式：
  
  ``innodb_buffer_pool_size``= 系统可用内存 - 系统正常运行内存 - （峰值时的连接数 * 每个连接需要的内存）
  
  不过更大的缓冲池会使得mysql服务在重启和关闭的时候花费很长时间  **比如启动时的系统预热**

- ``innodb_log_file_size``

  ![image-20200525151919811](E:\Typora\imgs\image-20200525151919811.png)

  ``innodb_log_file_size`` * ``innodb_log_files_in_group``不能超过最大值

由于事务修改的数据和索引通常会映射到表空间的随机位置里，所以这些变更到磁盘需要很对随机IO。

innodb用日志把**随机IO变成顺序IO**（追加的方式写入），一旦日志安全写到磁盘，事务就持久化了。当然，Innodb最后会把变更写到数据文件，因为日志文件是有固定的大小的。innodb的日志是环形方式写的：当写到日志的尾部，会重新跳转到开头继续写。 innodb使用一个后台线程智能地刷新这些变更到数据文件，相当于缓和了IO系统的压力。

对于  ``innodb_log_file_size``，如果太大，恢复起来太慢，太小，当一个日志文件写满后，innodb会自动切换到另一个日志文件，而且会触发数据库的checkpoint ，这回导致innodb缓存脏页的小批量刷新，会明显降低innodb的性能。一个经验是，日志文件的全部大小应该足够容纳服务器一个小时的活动内容。



## 事务与锁

1.四种隔离级别

​	``READ UNCOMMITED``    ``READ COMMITED``   ``REAPEATABLE READ``   ``SERIALIZABLE``

​	是SQL的标准定义，不同数据库会有不同的实现，MySQL在 ``REPEATABLE READ``的隔离级别下，是可以避免幻读的

2.版本链

​	对于INNODB的表，它的行记录都有两个必要的隐藏列：

- trx_id 每次对某条记录进行改动时，都会把对应的事物ID赋值给改trx_id
- roll_pointer 每次对记录进行改动时，这个隐藏列会存一个指针，通过这个指针可以找到该记录修改前的信息

3.readview

​	对于``READ UNCOMMITED``，直接读取最新的记录版本就行；``SERIALIZABLE``,使用加锁的方式来访问记录；``READ COMMITED``和``REAPEATABLE READ``就需要通过版本链和``readview``配合完成了，核心问题就是**判断版本链中哪个版本应该是当前事务应该读的**

​	实际上版本并非物理存在的，而是通过undo log 计算出来的。

​	readview中比较重要的四个属性 ：

- ``m_ids``  生成``readview``时，当前系统活跃（未提交的）读写事务的事务id列表
- ``min_trx_id`` 生成``readview``时，当前系统活跃（未提交的）读写事务的事务id列表``m_ids``的最小值
- ``max_trx_id`` 生成``readview``时系统应该分配给下一个事务的id值
- ``creator_trx_id`` 生成该``readview``的事务的事务id

4.MVCC

在使用``READ COMMITED``和``REAPEATABLE READ``两种隔离级别的事务在执行普通的select操作时访问记录的**版本链**的过程，可以使不同事务读-写并发执行，提高并发性能（ 不涉及到加锁），主要是能高效地读

``READ COMMITED``和``REAPEATABLE READ``很大不同：生成``readview``时机不同：

- ``READ COMMITED``每次进行select操作都会生成一个``readview``

- ``REAPEATABLE READ``只在第一次select操作前生成一个``readview``,之后的查询操作重复使用这个``readview``从而实现可重复读

5.锁

- 读锁  共享锁  select * from t1  where id  = 1 lock in share mode

- 写锁  排它锁 select ... for update

- select   普通的select操作，Innodb不会加任何锁  也就是事物A对某行加了写锁，事物B 执行普通的select操作是不会阻塞的。 想要select操作也加锁，可以：

  select ... for update  写锁

  select * from t1  where id  = 1 lock in share mode 读锁

- Gap锁 为了解决幻读

  

## 高可用和可扩展

### 复制

原则：一个备库实例只有一个主库，一个主库可以由多个备库；每个备库必须有一个唯一的服务器ID

- 基于行的复制

  优点：几乎所有场景都适用，不需要串行化；不要建立查询计划并执行查询（减少CPU的使用）；更新一个不存在的行 时会报错；

  缺点：不知道执行了哪些SQL，不利于找到问题；

- 基于语句的复制（逻辑复制）

  优点：不占带宽，一条更新好几兆数据的语句可能只占几十个字节；出现问题好定位，灵活，表的列顺序不同，数据类型兼容都可以更新

  缺点：正在使用触发器或者存储过程，会有问题；必须串行化；

  **步骤**：

  1.在主库上，根据事务的提交顺序记录二进制日志

  2.备库启动一个IO线程与主库建立一个普通的客户端连接，备库会在主库上启动一个线程，执行binlog dump指令，将二进制日志的数据发送至备库（如果备库，会对主库造成很大的负载，备库将接受到的数据记录在relay log（中继日志）。

  3.备库的启动一个SQL线程从relay log中读取事件并在备库执行，实现备库数据的更新。**主库并发运行的查询只能在备库上串行化执行，因为备库只有一个SQL线程更新数据**，这是一个性能瓶颈。

  ![image-20200531170246859](E:\Typora\imgs\image-20200531170246859.png)

- 一主多备   适用于少量写大量读，备库只读，主库可以读和写。 当备库太多对主库造成过大的工作负载时，可以通过一个分发库解决。分发库实际上也是一个备库，唯一的目的就是提取主库的binary log文件，多个备库连接到主库从而降低主库的负载。

  ###### 	存在延迟，因而能读到脏数据   how to solve it?

  可以同步写操作：在多个备库上执行``MASTER_POS_WAIT()``,可以阻塞主库务直到备库赶上了设置的主库同步点，相当于设置了一个``CyclicBarrier``。但是当一个备库出现复制延迟时，可能花很长时间才能完成复制。

- 双主复制   会有很多冲突，比如同时向两台主库写数据，只能在两台服务器之间共享串行化写入 。可以采用主动-被动模式下的双主复制

### 避免单点失效

一般都是为系统增加冗余：增加空余容量和重复组件。

  

### 可扩展

- **垂直扩展**  

  在单机的基础上买更多强悍的硬件，但是总会遇到性能瓶颈：

  1.复杂的查询在MySQL内部是单线程的，只能使用一个CPU，无法利用多核

  2.数据非常庞大的时候，总会出现无法缓存的情况，内存成为瓶颈，导致很高的磁盘利用率。

- **水平扩展**   复制，拆分，数据分片

  1.什么时候要数据分片？

  ​	主从模式是适用于读多写少的场景。只有单台主库，无论备库多么多，写容量始终是无法扩展的。想要扩展写容量，就必须切分数据。



  

  